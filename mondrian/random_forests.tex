\documentclass{article}
\input{preamble.tex}
\bibliography{refs}

\title{Uniform Inference for Mondrian Trees and Forests}
\author{William G.\ Underwood}

\begin{document}

\maketitle







\section{Setup}

Let $(X_i, Y_i)$ be i.i.d.\ samples from a distribution
on $[0,1]^d \times [0,1]$.
Write $\mu(x) = \E[Y_i \mid X_i = x]$
and $\varepsilon_i = Y_i - \mu(X_i)$.
Suppose that $X_i$ has a continuous density function $f_X(x)$
which is bounded away from zero on $[0,1]^d$.
For $\lambda>0$ let $\cT_\lambda$ be a Mondrian tree
(independent of the data)
on $[0,1]^d$ with lifetime $\lambda$ as defined
by \cite{mourtada2020minimax}.
Denote the cell of $\cT_\lambda$ containing a point $x$
by $\cT_\lambda(x)$.
The tree estimator of $\mu$ is
%
\begin{align*}
  \widehat\mu_{\rmT}(x)
  =\frac{\sum_{i=1}^n Y_i
  \I\big\{ X_i \in \cT_\lambda(x) \big\}}
  {\sum_{i=1}^n
  \I\big\{ X_i \in \cT_\lambda(x) \big\}},
\end{align*}
%
and its associated forest estimator is
%
\begin{align*}
  \widehat\mu_{\rmF}(x)
  =\frac{1}{B}
  \sum_{b=1}^B
  \frac{\sum_{i=1}^n Y_i
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}}
  {\sum_{i=1}^n
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}}
\end{align*}
%
where $B$ trees are grown independently of the data
and of each other.
Note how each tree is equally weighted at every point $x$.
If instead we give more weight to those trees which place many
data points in $\cT^b_\lambda(x)$,
we obtain the \emph{Mondrian kernel random forest}
\cite{scornet2016random} defined by
%
\begin{align*}
  \widehat\mu_{\rmK}(x)
  = \frac{\sum_{b=1}^B \sum_{i=1}^n Y_i
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}}
  {\sum_{b=1}^B \sum_{i=1}^n
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}}.
\end{align*}
%
These are shown to perform empirically just as well as
true random forests \cite{scornet2016random}.
They are also easier to analyse as they converge
uniformly almost surely to the Laplace kernel
Nadaraya--Watson estimator as $B \to \infty$.
A proposed avenue is to extend the ``local averaging''
of random forests to local polynomial fitting with a random forest kernel:
%
\begin{align*}
  \text{Mondrian kernel random forest}
  &\longleftrightarrow
    \text{Laplace kernel Nadaraya--Watson} \\
  \text{Mondrian kernel local polynomial regression}
  &\longleftrightarrow
    \text{Laplace kernel local polynomial regression}.
\end{align*}
%
This should enable the following results.
%
\begin{itemize}

  \item
    Minimax rates of convergence for \emph{all} H{\"o}lder classes
    (current random forest results restrict to Lipschitz or $\cC^2$).

  \item
    Strong approximation via the Yurinskii coupling
    for local polynomial regression.

\end{itemize}
%
However it is not clear what the benefit would be over using
Laplace kernel regression directly.
It seems unlikely that there would be a computational benefit
since the fast Fourier transform allows exact computation of
the Nadaraya--Watson estimator in $O(n \log n)$ time.
We note that \cite{davies2014random}
suggest that some data-dependent kernel random forests
can outperfom certain kernel methods in practice.




\section{Results}

\subsection{Approach 1: strong approximation
  for an individual tree}

We find a conditionally Gaussian strong approximation for each
tree estimator.

\begin{lemma}[KMT approximation for Mondrian tree regression]
  \label{lem:kmt}

  \TODO{check the scaling here}
  There is a process $Z_n^\cT(x)$ which is conditionally
  Gaussian and conditionally mean-zero (conditioning on $\cT$)
  satisfying
  %
  \begin{align*}
    \P\left(
    \sup_{x \in [0,1]^d}
    \left|
    \sqrt{\frac{\lambda^d}{n}}
    \sum_{i=1}^n
    \varepsilon_i
    \I\big\{ X_i \in \cT_\lambda(x) \big\}
    - Z^\cT_n(x)
    \right|
    > C (t + \log n)
    \sqrt{\frac{\lambda^d}{n}}
    \, \Bigm| \,
    \cT_\lambda
    \right)
    &\leq
      C e^{-t}
  \end{align*}
  %
  for all $t>0$ and a universal positive constant $C$.
  Further, the conditional covariance structure is the same.

\end{lemma}

\begin{proof}[Lemma~\ref{lem:kmt}]

  Let $\cT_{\lambda,1}, \ldots, \cT_{\lambda,K}$
  enumerate the cells of $\cT_\lambda$
  and define $k(x, \cT_\lambda) = k \iff x \in \cT_{\lambda,k}$.
  Set
  $U_i = \frac{\varepsilon_i}{2}
  + k(X_i, \cT_\lambda)$,
  noting
  $\I\big\{ X_i \in \cT_\lambda(x) \big\}
  = \I\{\lfloor U_i \rfloor = k(x, \cT_\lambda)\}$
  and
  $\varepsilon_i = 2(U_i - \lfloor U_i \rfloor)$.
  Let
  $g_n(U_i, x) = 2 \sqrt{\lambda^d} (U_i - \lfloor U_i \rfloor)
  \I\{\lfloor U_i \rfloor = k(x, \cT_\lambda)\}$
  so that
  $ \sqrt{\frac{\lambda^d}{n}}
  \sum_i \varepsilon_i \I\big\{ X_i \in \cT_\lambda(x) \big\}
  = \frac{1}{\sqrt n} \sum_i g_n(U_i,x)$.
  Next, observe that
  $U_i$ are i.i.d.\ given $\cT_\lambda$ and that
  $\E[g_n(U_i, x)] = 0$.
  We also have
  $\|g_n(\cdot, x)\|_\TV \leq 2 \sqrt{\lambda^d}$
  and since the process depends only on finitely many $x$ values
  (the center of each cell for example),
  we can embed $x$ into $\R$ and
  so the result follows by Lemma~A.1 from
  \cite{cattaneo2022uniform}
  applied conditionally on $\cT_\lambda$.
\end{proof}


This approach does not give a Gaussian approximation
for the forest estimator,
as it is not clear how to combine Gaussian approximations
for different trees:
although the Mondrian trees are independent,
the tree estimators depend on the same data samples.
At the forest level we lose the Haar basis
(locally constant) property
so cannot couple the entire forest to a Gaussian
(even conditionally).

\subsection{Approach 2: Yurinskii approximation
  for the Mondrian random forest}

By discretizing the centered and scaled forest estimator
and then applying Yurinskii's coupling in supremum norm
\cite{belloni2019conditional}
we can obtain a strong approximation for the
Mondrian random forest estimator.
In order to show this we need good bounds on the
number of cells in the common refinement of a Mondrian
random forest.



\subsection{Approach 3: Laplace approximation
  for the Mondrian kernel random forest}

Mondrian kernel random forests
approximate the Laplace kernel regression estimator if the forest
has many trees \cite{balog2016mondrian}.
To see this apply the restriction property for Mondrian processes.
Thus we can use Yurinskii's coupling for strong approximation
in $d$ dimensions as is well-known for kernel regression.
Note that $\lambda$ is exactly the inverse bandwidth.
The centered and scaled numerator of the Mondrian kernel
random forest estimator is
%
\begin{align*}
  \frac{1}{B}
  \sum_{b=1}^B
  \sqrt{\frac{\lambda^d}{n}}
  \sum_{i=1}^n
  \varepsilon_i
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
\end{align*}
%
and by the restriction property of Mondrian processes
\cite{mourtada2020minimax},
uniformly in $x$ and realizations of the data,
%
\begin{align*}
  \frac{1}{B}
  \sum_{b=1}^B
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
  \to
  \P\big( X_i \in \cT^b_\lambda(x) \mid X_i \big)
  = e^{-\lambda \|X_i - x \|_1}
\end{align*}
%
almost surely as $B \to \infty$.
The rate of this convergence is governed by the conditional variance
of the left-hand side:
%
\begin{align*}
  \Var\left[
  \frac{1}{B}
  \sum_{b=1}^B
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
  \Bigm| X_i
  \right]
  &=
    \frac{1}{B}
    \Var\left[
    \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
    \bigm| X_i
    \right]
    =
    \frac{1}{B}
    \P\big( X_i \in \cT^b_\lambda(x) \mid X_i \big)
    \big( 1 -
    \P\big( X_i \in \cT^b_\lambda(x) \mid X_i \big)
    \big) \\
  &=
    \frac{1}{B}
    e^{-\lambda \|X_i - x \|_1}
    \big( 1 - e^{-\lambda \|X_i - x \|_1} \big)
    \leq
    \frac{1}{B}.
\end{align*}
%
Thus the forest is approximated as
%
\begin{align*}
  \frac{1}{B}
  \sum_{b=1}^B
  \sqrt{\frac{\lambda^d}{n}}
  \sum_{i=1}^n
  \varepsilon_i
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
  \approx
  \sqrt{\frac{\lambda^d}{n}}
  \sum_{i=1}^n
  \varepsilon_i
  e^{-\lambda \|X_i - x \|_1}
\end{align*}
%
which is exactly the numerator for
the Nadaraya--Watson estimator with a Laplace kernel.
Now we apply Yurinskii's coupling for the supremum norm
\cite{belloni2019conditional}.
Take $\xi_i(x) = \lambda^{d/2} n^{-1/2}
\varepsilon_i e^{-\lambda \|X_i - x \|_1}$
and discretize $x$ at level $\delta$.
Then
$\sum_i \E\left[\|\xi_i\|_2^2 \|\xi_i\|_\infty \right]
\lesssim \delta^{-d} \sqrt{\lambda^d \log n / n}$
and so we have a Gaussian coupling whenever
$\delta^{-d} \sqrt{\lambda^d (\log n)^3 / n} \to 0$.
Chaining with Bernstein's inequality shows that
the fluctuations in the process are of the order
$\lambda \delta \sqrt{\log n}$,
so we need
%
\begin{align*}
  \delta^{-d} \sqrt{\lambda^d (\log n)^3 / n} \to 0
  &\iff \delta \gg
    \left( \frac{\lambda^d (\log n)^3}{n} \right)^{1/2d}
  \\
  \lambda \delta \sqrt{\log n} \to 0
  &\iff \delta \ll \frac{1}{\lambda \sqrt{\log n}}
\end{align*}
%
and this is possible whenever
$\lambda^{3d} \ll n$, up to logs.
This is almost exactly the analogous condition $nh^3 \to \infty$ for
normality in kernel estimation.
This condition will be matched by a lower bound on
$\lambda$ from the bias,
which probably decreases like $1/\lambda$.
We can possibly improve the bias
(both to capture smoothness and remove boundary effects)
by using local polynomial fits
rather than local constant fits with the Mondrian kernel.
The scaled denominator of the Mondrian kernel random forest estimator
converges as
%
\begin{align*}
  \frac{1}{B}
  \sum_{b=1}^B
  \frac{\lambda^d}{n}
  \sum_{i=1}^n
  \I\big\{ X_i \in \cT^b_\lambda(x) \big\}
  \to
  \lambda^d \,
  \P\big(X_i \in \cT_\lambda^b(x) \big).
\end{align*}
%
almost surely as $n,B \to \infty$.
This quantity is approximately $2^d f_X(x)$ for interior points $x$
and approximately $f_X(x)$ at corner points.
At non-corner boundary points it is between these two values.

\pagebreak

\subsection{Properties of Mondrian forests}



\begin{lemma}[Expected number of cells in a Mondrian forest refinement]
  \label{lem:refinement}

  Take $C = \bigotimes_{j=1}^d C^j$
  and $\lambda_b > 0$ for $1 \leq b \leq B$.
  Let $T_b \sim \MP(C, \lambda_b)$ be independent Mondrian processes
  and write $\bigwedge_{b=1}^B T_b$ for the common refinement
  of their partitions.
  Then the expected number of cells in this refinement is
  %
  \begin{align*}
    \E\left[\# \bigwedge_{b=1}^B T_b \right]
    &= \prod_{j=1}^d \left(
      1 + |C^j| \sum_{b=1}^B \lambda_b
      \right).
  \end{align*}
  %
\end{lemma}








\begin{proof}[Lemma~\ref{lem:refinement}]

  By \cite[Proposition~2]{mourtada2020minimax}
  we have the result for a single tree:
  %
  \begin{align*}
    \E\left[\# T_b \right]
    &= \prod_{j=1}^d \left(
      1 + |C^j| \lambda_b
      \right).
  \end{align*}
  %
  We proceed by induction on $B$.
  Denote the restriction of a tree $T$ to a cell $C$ by $T \cap C$.
  By the tower law,
  %
  \begin{align*}
    \E\left[\# \bigwedge_{b=1}^B T_b \right]
    &=
      \E\left[
      \sum_{C_B \in T_B}
      \#
      \left(
      \bigwedge_{b=1}^{B-1} (T_b \cap C_B)
      \right)
      \right]
      = \E\left[
      \sum_{C_B \in T_B}
      \E\left[
      \#
      \left(
      \bigwedge_{b=1}^{B-1} (T_b \cap C_B)
      \right)
      \biggm| T_B
      \right]
      \right].
  \end{align*}
  %
  Now by the restriction property of Mondrian processes
  \cite[Fact~2]{mourtada2020minimax},
  observe that $T_b \cap C_B \sim \MP(C_B, \lambda_b)$
  conditional on $T_B$.
  Then by the induction hypothesis,
  %
  \begin{align*}
    \E\left[
    \#
    \left(
    \bigwedge_{b=1}^{B-1} (T_b \cap C_B)
    \right)
    \biggm| T_B
    \right]
    &=
      \prod_{j=1}^d \left(
      1 + |C_B^j| \sum_{b=1}^{B-1} \lambda_b
      \right)
      = \E\big[
      \# T_{C_B} \mid T_B
      \big]
  \end{align*}
  %
  where $T_{C_B} \sim \MP(C_B, \sum_{b=1}^{B-1} \lambda_B)$
  independently, conditional on $T_B$,
  by the result for a single tree.
  The restriction property finally shows that
  $\sum_{C_B \in T_B} \# T_{C_B}$ is equal in distribution
  to $\# T$ where $T \sim \MP(C, \sum_{b=1}^B \lambda_b)$
  and so
  %
  \begin{align*}
    \E\left[\# \bigwedge_{b=1}^B T_b \right]
    &=
      \E\left[
      \sum_{C_B \in T_B}
      \E\big[
      \# T_{C_B} \mid T_B
      \big]
      \right]
      =
      \E\big[\# T \big]
      = \prod_{j=1}^d \left(
      1 + |C^j| \sum_{b=1}^B \lambda_b
      \right).
  \end{align*}
\end{proof}






\begin{lemma}[Tail bound for the number of cells in a Mondrian tree]
  \label{lem:cells_tail}

  Let $T \sim \MP(C, \lambda)$. Then
  %
  \begin{align*}
    \P\left(\# T >
    3
    (1 + \lambda |C|)^d
    (t + 1 + d \log(1 + \lambda |C|)
    \right)
    &\leq
      e^{-t}.
  \end{align*}

\end{lemma}


\begin{proof}[Lemma~\ref{lem:cells_tail}]

  We refer to this method as the ``subcell trick''
  and attribute it to \cite{mourtada2017universal}.
  For $\varepsilon > 0$ partition $C$ into
  at most $(1 + 1/\varepsilon)^d$ cells $C_\varepsilon \in \cC_\varepsilon$
  with side lengths at most $(|C^1| \varepsilon, \ldots, |C^d| \varepsilon)$.
  Since a split in $T$ induces a split in some
  $T \cap C_\varepsilon$,
  %
  \begin{align*}
    \P\left(\# T > t \right)
    &\leq
      \P\left(\sum_{C_\varepsilon \in \cC_\varepsilon}
      \# (T \cap C_\varepsilon) > t \right)
      \leq
      \sum_{C_\varepsilon \in \cC_\varepsilon}
      \P\left(
      \# (T \cap C_\varepsilon) >
      \frac{t}{\# \cC_\varepsilon}
      \right).
  \end{align*}
  %
  Now $\# (T \cap C_\varepsilon)$ is dominated by a Yule process
  with parameter $|C_\varepsilon|$ stopped at time $\lambda$
  \cite[proof of Lemma~2]{mourtada2017universal},
  so using that fact that if
  $X \sim \Yule(a)$
  then $\P(X_t > n) \leq (1-e^{-at})^{n-1}$,
  %
  \begin{align*}
    \P\left(\# T > t \right)
    &\leq
      \# \cC_\varepsilon \,
      (1 - e^{-\lambda |C| \varepsilon})^{t / \# \cC_\varepsilon - 1}
      \leq
      (1 + 1/\varepsilon)^d
      (1 - e^{-\lambda |C| \varepsilon})^{t (1 + 1/\varepsilon)^{-d} - 1}.
  \end{align*}
  %
  Setting $\varepsilon = \frac{1}{\lambda |C|}$,
  noting $1-1/e \leq e^{-1/3}$
  and replacing $t$ by
  $3 (1 + \lambda |C|)^d
  (t + 1 + d \log(1 + \lambda |C|)$
  yields
  %
  \begin{align*}
    &\P\left(\# T > t \right)
      \leq
      (1 + \lambda |C|)^d
      (1 - 1/e)^{t (1 + \lambda |C|)^{-d} - 1}
      \leq
      2 (1 + \lambda |C|)^d
      e^{-t (1 + \lambda |C|)^{-d} / 3}, \\
    &\P\left(\# T >
      3
      (1 + \lambda |C|)^d
      (t + 1 + d \log(1 + \lambda |C|)
      \right)
      \leq
      e^{-t}.
  \end{align*}
\end{proof}



\begin{definition}[Canonical order of cells in a Mondrian tree]

  Let $T \sim \MP(C, \lambda)$.
  Each cell in a fixed realization of $T$ can be described by
  a word from the alphabet $\{l, r\}$,
  where $l$ indicates the cell to the left of a split
  and $r$ indicates the cell to the right.
  For example, if there are no splits we have one cell
  described by the empty word.
  After one split there are two cells, denoted
  $l$ and $r$.
  Now suppose that the cell $r$ splits again, giving two splits and three cells,
  denoted $l$, $rl$ and $rr$.
  Define the canonical ordering of the cells of $T$ by applying
  the lexicographic order to their words, with $l < r$.
  Note that it does not matter which coordinate each split occurs in:
  in two dimensions, $l$ might refer to the ``left'' or ``bottom''
  and $r$ to the ``right'' or ``top'' cell.

\end{definition}




\begin{lemma}[Cells in a Mondrian tree have identically distributed shapes]
  \label{lem:cells_identically_distributed}

  Let $T \sim \MP(C, \lambda)$
  with canonically ordered cells
  $C_1, \ldots, C_{\# T}$.
  For any $\varepsilon_1, \ldots, \varepsilon_d \geq 0$
  and $1 \leq i \leq k$, we have
  %
  \begin{align*}
    \P\left(
    |C_i^1| \leq \varepsilon_1,
    \ldots, |C_i^d| \leq \varepsilon_d,
    \# T = k
    \right)
    &=
      \P\left(
      |C_1^1| \leq \varepsilon_1,
      \ldots, |C_1^d| \leq \varepsilon_d,
      \# T = k
      \right).
  \end{align*}
  %
  Therefore by marginalizing over $\# T$,
  if $E_j$ are i.i.d.\ $\Exp(1)$ variables,
  %
  \begin{align*}
    \P\left(
    |C_i^1| > \varepsilon_1,
    \ldots, |C_i^d| > \varepsilon_d
    \right)
    &=
      \prod_{j=1}^d
      \P\left(
      \frac{E_j}{\lambda} \wedge |C^j|
      > \varepsilon_j
      \right)
      = \prod_{j=1}^d
      \I\{|C^j| > \varepsilon_j\}
      e^{-\lambda \varepsilon_j}.
  \end{align*}

\end{lemma}



\begin{proof}[Lemma~\ref{lem:cells_identically_distributed}]

  Let $w$ be the word associated with the cell $C_i \in T$.
  Note that $i=1$ if and only if $r \notin w$.
  So suppose $r \in w$.
  Let $\widetilde w$ be the word obtained by replacing all occurences
  of $r$ in $w$ with an $l$.
  Each such replacement corresponds to a split in $T$.
  Let $\widetilde T$ be the same process as $T$ but with the following modification:
  for each split where a replacement was made,
  change the uniform random variable $U$
  (from the definition of $T$) to $1-U$.
  Since $U$ is independent of everything else in the construction of $T$,
  we observe that $\widetilde T \sim \MP(C, \lambda)$ also.
  Further, there is almost surely exactly one cell in $\widetilde T$
  which has the same shape as $C$.
  Denote this cell $\widetilde C$ and note that
  the replacements imply that its word in $\widetilde T$
  is $\widetilde w$.
  Thus $\widetilde C = \widetilde C_1$ in $\widetilde T$ and so
  $(|C_i^1|, \ldots, |C_i^d|, \# T)
  = (|\widetilde C_1^1|, \ldots, |\widetilde C_1^d|, \# \widetilde T)$
  a.s.
  Equality of the distributions follows immediately.
\end{proof}




\begin{lemma}[Tail bound on largest Mondrian cell]
  \label{lem:largest_cell_tail}

  Let $T \sim \MP(C, \lambda)$.
  For any $\varepsilon > 0$,
  %
  \begin{align*}
    \P\left(
    \max_{C' \in T}
    \max_{1 \leq j \leq d}
    |C'^j| > \varepsilon
    \right)
    &\leq
      5d (1 + \lambda |C|)^{d+1}
      e^{-\lambda \varepsilon}.
  \end{align*}
  %
  and so also
  %
  \begin{align*}
    \P\left(
    \max_{C' \in T}
    |C'| > \varepsilon
    \right)
    &\leq
      5 d (1 + \lambda |C|)^{d+1}
      e^{-\lambda \varepsilon / d}.
  \end{align*}
  %
\end{lemma}


\begin{proof}[Lemma~\ref{lem:largest_cell_tail}]

  Let $C_i$ be the canonically ordered cells of $T$
  and take $k \geq 1$.
  By union bounds and
  Lemma~\ref{lem:cells_identically_distributed},
  %
  \begin{align*}
    \P\left(
    \max_{C' \in T}
    \max_{1 \leq j \leq d}
    |C'^j| > \varepsilon
    \right)
    &\leq
      \sum_{l=1}^k
      \P\left(
      \max_{1 \leq i \leq l}
      \max_{1 \leq j \leq d}
      |C_i^j| > \varepsilon,
      \# T = l
      \right)
      + \P\left( \# T > k \right) \\
    &\leq
      \sum_{l=1}^k
      \sum_{i=1}^l
      \sum_{j=1}^d
      \P\big(
      |C_i^j| > \varepsilon,
      \# T = l
      \big)
      + \P\left( \# T > k \right) \\
    &\leq
      \sum_{l=1}^k
      l d \,
      \P\big(
      |C_1^j| > \varepsilon,
      \# T = l
      \big)
      + \P\left( \# T > k \right) \\
    &\leq
      k d \,
      \P\big(|C_1^j| > \varepsilon \big)
      + \P\left( \# T > k \right).
  \end{align*}
  %
  For the first term we use the exact distribution of
  $C_1$ from Lemma~\ref{lem:cells_identically_distributed}
  and for the second term we apply Lemma~\ref{lem:cells_tail}.
  %
  \begin{align*}
    \P\left(
    \max_{C' \in T}
    \max_{1 \leq j \leq d}
    |C'^j| > \varepsilon
    \right)
    &\leq
      k d \, \P\big(|C_1^j| > \varepsilon \big)
      + \P\left( \# T > k \right) \\
    &\leq
      kd \, e^{-\lambda \varepsilon}
      + 2 (1 + \lambda |C|)^d
      e^{-k (1 + \lambda |C|)^{-d} / 3}.
  \end{align*}
  %
  Finally set
  $k = \big\lceil 3 \lambda \varepsilon (1 + \lambda |C|)^d \big\rceil$
  and note the bound is trivial unless $\varepsilon \leq |C|$.
  %
  \begin{align*}
    \P\left(
    \max_{C' \in T}
    \max_{1 \leq j \leq d}
    |C'^j| > \varepsilon
    \right)
    &\leq
      \big( 3 \lambda \varepsilon (1 + \lambda |C|)^d + 1 \big)
      d \, e^{-\lambda \varepsilon}
      + 2 (1 + \lambda |C|)^d
      e^{-\lambda \varepsilon} \\
    &\leq
      3d (1 + \lambda |C|)^{d+1}
      e^{-\lambda \varepsilon}
      + 2 (1 + \lambda |C|)^d
      e^{-\lambda \varepsilon} \\
    &\leq
      5d (1 + \lambda |C|)^{d+1}
      e^{-\lambda \varepsilon}.
  \end{align*}
  %
\end{proof}


\begin{lemma}[Some inequalities regarding forest refinements]
  \label{lem:refinement_inequalities}

  Let $T_b$ be trees on a $d$-dimensional cell $C$
  for $1 \leq b \leq B$.
  Then
  %
  \begin{align*}
    \# \bigwedge_{b=1}^B T_b
    &\leq \prod_{b=1}^B \# T_b
  \end{align*}
  %
  and this bound is achievable whenever $B \leq d$.
  If $\# T_b^j$ denotes the number of cuts
  made by $T_b$ in dimension $j$ then
  %
  \begin{align*}
    \# \bigwedge_{b=1}^B T_b
    &\leq \prod_{j=1}^d
      \sum_{b=1}^B \# T_b^j
  \end{align*}
  %
  and this is bound is achievable whenever $B \geq d$.

\end{lemma}

\begin{proof}[Lemma~\ref{lem:refinement_inequalities}]

  The first inequality follows because every cell in
  $\bigwedge_b T_b$ is the intersection of cells
  $C_b \in T_b$ for $1 \leq b \leq B$.
  This bound is achievable when $B \leq d$ by setting
  $T_b$ to be a tree with cuts only in dimension $b$,
  so that every such intersection of cells
  gives a cell in the refinement.

  For the second inequality we construct a new forest of trees.
  In particular, for each $1 \leq j \leq d$ define
  $A_j$ to be the set of locations in $C^j$ where some tree $T_b$
  makes a cut in dimension $j$.
  Now define $T'_j$ to be a tree which has cuts
  only in dimension $j$ and at the locations prescribed by $A_j$.
  Clearly since every cut in $T'_j$
  comes from a cut from $T_b$ in dimension $j$,
  we have $\# T'_j \leq \sum_b \# T_b^j$.
  Applying the first inequality to the new forest yields
  $\# \bigwedge_j T'_j \leq \prod_j \# T'_j
  \leq \prod_j \sum_b \# T_b^j$.
  Finally note $\bigwedge_b T_b$
  is a subtree of $\bigwedge_j T'_j$ and the result follows.
  This bound is achievable when $B \geq d$ by fixing
  $T_b$ to have cuts only in dimension $b$ when $b \leq d$
  and to be empty otherwise.
  %
\end{proof}




\begin{lemma}[Tail bound on the number of cells in a Mondrian forest refinement]
  \label{lem:refinement_tail}

  Let $T_b \sim \MP(C, \lambda)$ be i.i.d.\ for $1 \leq b \leq B$.
  Then
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > 3^d 2^{d^2} B^d (1+\lambda|C|)^d
    \left(
    t + \log\left( 2^{d+1} dB (1 + \lambda |C|)^d \right)
    \right)^d
    \right)
    &\leq e^{-t}.
  \end{align*}


\end{lemma}






\begin{proof}[Lemma~\ref{lem:refinement_tail}]

  We begin with a rather coarse estimate and refine it using
  the subcell trick.
  By Lemma~\ref{lem:refinement_inequalities}
  and union bounds,
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > t
    \right)
    &\leq
      \P\left(
      \prod_{j=1}^d
      \sum_{b=1}^B \# T_b^j
      > t
      \right)
      \leq
      d\,
      \P\left(
      \sum_{b=1}^B \# T_b
      > t^{1/d}
      \right)
      \leq
      dB\,
      \P\left(
      \# T_b > \frac{t^{1/d}}{B}
      \right).
  \end{align*}
  %
  Now by the subcell trick, partition $C$ into
  at most $(1 + 1/\varepsilon)^d$ cells
  $C_\varepsilon \in \cC_\varepsilon$
  with side lengths at most
  $(|C^1| \varepsilon, \ldots, |C^d| \varepsilon)$.
  Since a split in $\bigwedge_b T_b$ induces a split
  in at least one of
  $\bigwedge_b (T_b \cap C_\varepsilon)$,
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > t
    \right)
    &\leq
      \P\left(
      \sum_{C_\varepsilon \in \cC_\varepsilon}
      \# \bigwedge_{b=1}^B (T_b \cap C_\varepsilon)
      > t
      \right)
      \leq
      \sum_{C_\varepsilon \in \cC_\varepsilon}
      \P\left(
      \# \bigwedge_{b=1}^B (T_b \cap C_\varepsilon)
      > \frac{t}{\# \cC_\varepsilon}
      \right).
  \end{align*}
  %
  Applying the coarse estimate above gives
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > t
    \right)
    &\leq
      \# \cC_\varepsilon
      dB\,
      \P\left(
      \# (T_b \cap C_\varepsilon)
      > \frac{t^{1/d}}{B \# \cC_\varepsilon^{1/d}}
      \right)
      \leq
      (1 + 1/\varepsilon)^d
      dB\,
      \P\left(
      \# (T_b \cap C_\varepsilon)
      > \frac{t^{1/d}}{B (1 + 1/\varepsilon)}
      \right)
  \end{align*}
  %
  By Lemma~\ref{lem:cells_tail}
  and setting $\varepsilon = \frac{1}{\lambda |C|}$,
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > t
    \right)
    &\leq
      2 (1 + 1/\varepsilon)^d
      dB\,
      (1 + \lambda |C| \varepsilon)^d
      e^{-t^{1/d} B^{-1} (1+1/\varepsilon)^{-1}
      (1 + \lambda |C| \varepsilon)^{-d} / 3} \\
    &\leq
      2^{d+1} dB (1 + \lambda |C|)^d
      e^{-t^{1/d} B^{-1} (1+\lambda |C|)^{-1}
      2^{-d} / 3}.
  \end{align*}
  %
  Finally replacing $t$ by
  $3^d 2^{d^2} B^d (1+\lambda|C|)^d
  \left(
    t + \log\left( 2^{d+1} dB (1 + \lambda |C|)^d \right)
  \right)^d$
  we have
  %
  \begin{align*}
    \P\left(
    \# \bigwedge_{b=1}^B T_b
    > 3^d 2^{d^2} B^d (1+\lambda|C|)^d
    \left(
    t + \log\left( 2^{d+1} dB (1 + \lambda |C|)^d \right)
    \right)^d
    \right)
    &\leq e^{-t}.
  \end{align*}
  %
\end{proof}



\begin{definition}[Active cells]

  For a point $x \in C$ and trees $T_b$ for $1 \leq b \leq B$
  we define the active cells in the refinement at $x$ by
  %
  \begin{align*}
    \cA(x)
    = \left\{
    C' \in \bigwedge_{b=1}^B T_b
    \text{ such that there exists some } b
    \text{ and } C'' \in T_b
    \text{ such that } C' \subseteq C''
    \text{ and } x \in C''
    \right\}.
  \end{align*}

\end{definition}



\begin{lemma}[Active cells]
  \label{lem:active_cells}

  Let $T_b \sim \MP(C, \lambda)$ be i.i.d.\ for $1 \leq b \leq B$.
  Then the number of active cells can be controlled pointwise by
  %
  \begin{align*}
    \P\left( \# \cA(x)
    > 2^{d^2} 3^d B^d (1+2dt)^d t^d
    \right)
    &\leq
      2^{d+5} dB (1 + 2 d \lambda |C|)^{d+1} e^{-t}.
  \end{align*}
  %
  and uniformly by
  %
  \begin{align*}
    \P\left(
    \sup_{x \in C} \# \cA(x)
    > 2^{d(d+3)} d^d B^d t^{2d}
    \right)
    &\leq
      2^{11d^2}
      B^{d+1} (t ^d + 1) (1 + 2 d \lambda |C|)^{2d+1} e^{-t}.
  \end{align*}
  %
\end{lemma}




\begin{proof}[Lemma~\ref{lem:active_cells}]

  For $\varepsilon > 0$ and $x \in C$
  define $C_x^{\varepsilon}$ as the cell with side $j$
  given by $[x_j - \varepsilon, x_j + \varepsilon] \cap C^j$
  for $1 \leq j \leq d$.
  Note that if $C' \in \cA(x)$ and
  $\max_b \max_{C_b} \max_j |C_b^j| \leq \varepsilon$
  then $C' \subseteq C_x^\varepsilon$.
  Therefore with $0 < \varepsilon \leq \lambda |C|$,
  %
  \begin{align*}
    \P\left( \# \cA(x) > t \right)
    &\leq
      \P\left(
      \# \bigwedge_{b=1}^B
      \left( T_b \cap C_x^{\varepsilon/\lambda} \right)
      > t
      \right)
      + \P\left(
      \max_{1 \leq b \leq B}
      \max_{C_b \in T_b}
      \max_{1 \leq j \leq d}
      |C_b^j| > \frac{\varepsilon}{\lambda}
      \right).
  \end{align*}
  %
  Thus by a union bound and
  Lemmas~\ref{lem:largest_cell_tail}
  and~\ref{lem:refinement_tail},
  noting that
  $|C_x^{\varepsilon/\lambda}| \leq 2 d \varepsilon / \lambda$,
  %
  \begin{align*}
    \P\left( \# \cA(x) > t \right)
    &\leq
      2^{d+1} dB (1 + 2 d \varepsilon)^d
      e^{-t^{1/d} B^{-1} (1 + 2 d \varepsilon)^{-1}
      2^{-d} / 3}
      + 5d B (1 + \lambda |C|)^{d+1}
      e^{-\varepsilon}.
  \end{align*}
  %
  Noting $\varepsilon \leq \lambda |C|$,
  replacing $t$ by
  $2^{d^2} 3^d B^d (1+2d\varepsilon)^d t^d$
  and setting $\varepsilon = t$ gives
  %
  \begin{align*}
    \P\left( \# \cA(x)
    > 2^{d^2} 3^d B^d (1+2dt)^d t^d
    \right)
    &\leq
      2^{d+1} dB (1 + 2 d \lambda |C|)^d e^{-t}
      + 5d B (1 + \lambda |C|)^{d+1}
      e^{-t} \\
    &\leq
      2^{d+3} dB (1 + 2 d \lambda |C|)^{d+1} e^{-t}, \\
    \P\left( \# \cA(x)
    > 2^{d(d+3)} d^d B^d t^{2d}
    \right)
    &\leq
      2^{d+5} dB (1 + 2 d \lambda |C|)^{d+1} e^{-t}.
  \end{align*}
  %
  Next note that $\cA(x)$ depends on $x$ only
  through $\bigwedge_b T_b(x)$ so that
  %
  \begin{align*}
    \P\left(
    \sup_{x \in C} \# \cA(x)
    > 2^{d(d+3)} d^d B^d t^{2d}
    \right)
    &=
      \P\left(
      \max_{C' \in \bigwedge_b T_b} \# \cA(C')
      > 2^{d(d+3)} d^d B^d t^{2d}
      \right) \\
    &\leq
      \sum_{l=1}^k
      \P\left(
      \max_{C' \in \bigwedge_b T_b} \# \cA(C')
      > 2^{d(d+3)} d^d B^d t^{2d},
      \# \bigwedge_{b=1}^B T_b = l
      \right)
      + \P\left(
      \# \bigwedge_{b=1}^B T_b > k
      \right) \\
    &\leq
      k \sup_{x \in C}
      \P\left( \# \cA(x)
      > 2^{d(d+3)} d^d B^d t^{2d}
      \right)
      + \P\left(
      \# \bigwedge_{b=1}^B T_b > k
      \right) \\
    &\leq
      2^{d+5} kdB (1 + 2 d \lambda |C|)^{d+1} e^{-t}
      + 2^{d+1} dB (1 + \lambda |C|)^d
      e^{-k^{1/d} B^{-1} (1+\lambda |C|)^{-1}
      2^{-d} / 3}.
  \end{align*}
  %
  Setting
  $k = \lceil 3^d 2^{d^2} B^d (1+\lambda|C|)^d t ^d \rceil$
  gives
  %
  \begin{align*}
    \P\left(
    \sup_{x \in C} \# \cA(x)
    > 2^{d(d+3)} d^d B^d t^{2d}
    \right)
    &\leq
      2^{11d^2}
      B^{d+1} (t ^d + 1) (1 + 2 d \lambda |C|)^{2d+1} e^{-t}.
  \end{align*}
  %
\end{proof}




\TODO{Now pg 27 on tablet to continue KMT notes}











\printbibliography

\end{document}